{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f53854",
   "metadata": {},
   "source": [
    "### **Part 1: Design the dimensional model**\n",
    "\n",
    "Create a **dbt-style data model** to support analytics\n",
    "\n",
    "Consider: How would someone use these tables to answer business questions about revenue, customer segments, and Organizations adoption?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb657dc5",
   "metadata": {},
   "source": [
    "## RIOT Analytics — dbt Project Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01352930",
   "metadata": {},
   "source": [
    "### A- Model Conception\n",
    "\n",
    "For the dbt modeling organization, I'm following a hybrid approach that combines medallion architecture with star schema design.\n",
    "\n",
    "Bronze and Silver layers follow the medallion pattern to ensure a structured flow of cleaning and validation transformations—raw data is ingested as-is (Bronze), then cleaned, typed, and validated (Silver).\n",
    "\n",
    "Gold layer implements a star schema as the foundation for both ad-hoc analytical queries and upstream transformations. The star schema provides a clean, intuitive model for SQL analysts to explore data directly, while also serving as the base for more complex pre-calculated queries and business-wide tables optimized for BI tools.\n",
    "\n",
    "Each layer is isolated in a separate schema (dataset) within the same BigQuery project, enabling:\n",
    "\n",
    "   - Clear logical boundaries between raw, cleaned, and analytical data\n",
    "   - Granular access control (analysts can query Gold without accessing Bronze)\n",
    "   - Independent materialization strategies per layer\n",
    "   - Cost tracking and performance monitoring by layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb24d6",
   "metadata": {},
   "source": [
    "![Data Flow Diagram](./annexe/dbt_model.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ef9a9",
   "metadata": {},
   "source": [
    "### Fact and dimension tables relationships\n",
    "\n",
    "![Data Flow Diagram](./annexe/stripe_star_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317299a",
   "metadata": {},
   "source": [
    "## B - Incremental model organization\n",
    "\n",
    "In a real data use case. We won't have static raw data, but usually a x-periodic new or updated data. Dbt offer some hands on incremental strategies to avoid re-transforming each time the whole dbt-project. One critea for pipelines is to ensure idempotency while doing incremental process\n",
    "\n",
    "### Idempotency Strategy\n",
    "\n",
    "### Timestamp-Based Interval Processing\n",
    "\n",
    "To ensure **idempotent and reproducible** data pipeline runs, all incremental models use **explicit date ranges** defined by `start_date` and `end_date` parameters rather than relying on high-water marks.\n",
    "\n",
    "---\n",
    "\n",
    "### Core Principle\n",
    "\n",
    "**Every dbt run processes a specific, bounded time interval:**\n",
    "- `start_date`: Beginning of the processing window (inclusive)\n",
    "- `end_date`: End of the processing window (non-inclusive)\n",
    "- Records selected: `WHERE date >= start_date AND date < end_date`\n",
    "\n",
    "---\n",
    "\n",
    "### Benefits\n",
    "\n",
    "1. **Idempotency:** Running the same date range multiple times produces identical results\n",
    "2. **Reproducibility:** Can reprocess any historical period on demand\n",
    "3. **Testability:** Easy to test specific date ranges in development\n",
    "4. **Debugging:** Clear boundaries for investigating data issues\n",
    "5. **Backfill control:** Explicit control over which periods to process\n",
    "\n",
    "### Incremental strategy\n",
    "\n",
    "By default we will apply merge strategy where we define a primary key and we ensure insert only new data or updated one. In case of state change and when tracking those changes are important (maybe like fct_subscriptions) we might use scd2 incremental logic that will gave us a sort validity interval for each data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172312a7",
   "metadata": {},
   "source": [
    "## C - Storage Strategy\n",
    "\n",
    "Medallion architecture consume a lot of storage space as data volume grows, we should take that into consideration for mid/long term. \n",
    "\n",
    "### Current Approach: BigQuery Native Tables\n",
    "\n",
    "For the initial implementation, all layers are stored as **BigQuery native tables/views**:\n",
    "\n",
    "| Layer | Storage Type | Rationale |\n",
    "|-------|-------------|-----------|\n",
    "| **Bronze** | BigQuery views | Zero storage cost, references seed data or source tables |\n",
    "| **Silver** | BigQuery tables | Fast query performance, native BigQuery optimizations |\n",
    "| **Gold** | BigQuery tables | Optimized for BI tools, leverages BigQuery caching |\n",
    "\n",
    "**Benefit:**\n",
    "- Simplicity of implementation since there is only one engine and less engineering between different ecosystems.\n",
    "\n",
    "\n",
    "### Futur Approach: To take into account  ---> Apache Iceberg for Bronze/Silver\n",
    "\n",
    "As data volume grows or requirements evolve, **Apache Iceberg** tables stored in **Cloud Storage** may be considered for Bronze and Silver layers:\n",
    "\n",
    "**When to consider?**\n",
    "- Multi-engine access patterns (Spark, Trino, Flink alongside BigQuery)\n",
    "- Desire for cloud-agnostic, open table format to avoid vendor lock-in\n",
    "- Data volume grows and storage costs become significant\n",
    "\n",
    "**Hybrid architecture with Iceberg:**\n",
    "\n",
    "**Gold layer remains in BigQuery native tables** for optimal BI performance.\n",
    "\n",
    "**Bronze and silver moves to apache iceberg**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e69f2d",
   "metadata": {},
   "source": [
    "## D- Retention strategy\n",
    "\n",
    "### Retention Policies by Layer\n",
    "\n",
    "Different layers have different retention requirements based on their purpose and access patterns:\n",
    "\n",
    "| Layer | Retention Period | Rationale | \n",
    "|-------|-----------------|-----------|\n",
    "| **Bronze** | 90 days | Raw data replicas for reprocessing and auditing. Source of truth remains in operational systems (Stripe). |\n",
    "| **Silver** | 2 years | Cleaned data for historical analysis and model retraining. Balances analytical needs with storage costs. |\n",
    "| **Gold** | 5+ years | Business-critical aggregates and metrics for long-term trend analysis, compliance, and reporting. |\n",
    "\n",
    "\n",
    "**Key principle:** Data becomes more valuable as it moves through the layers. Gold represents the refined, business-ready output that justifies extended retention for strategic analysis and regulatory compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670ce0c",
   "metadata": {},
   "source": [
    "## E- Macros Strategy\n",
    "\n",
    "### Purpose and Vision\n",
    "\n",
    "Establish a **reusable macros library** organized by function to standardize transformations, ensure data quality and ease of peer programming. The mid term idea is to be able to pick existing macros if enough to reach our transformations goal or add additionnal ones if some missing logic transformations. The long-term goal is to create a sort of low code library powered by an agentic AI to reach a high % of automation, allowing analysts to generate complex analytical queries without writing SQL.\n",
    "\n",
    "### Macro Categories\n",
    "\n",
    "#### 1. **SQL Core Macros**\n",
    "- **Purpose:** Fundamental building blocks for common SQL operations\n",
    "- **Examples:** CTE generation, sql mandatory/classic function creation\n",
    "\n",
    "#### 2. **Normalization Macros**\n",
    "- **Purpose:** Standardize data formats and business logic\n",
    "- **Examples:** A naming conventions (important in a long term view), date standardization ...\n",
    "\n",
    "\n",
    "#### 3. **Quality & Compliance Macros**\n",
    "- **Purpose:** Enforce data quality checks and regulatory requirements\n",
    "- **Examples:** PII masking/hashing, GDPR deletion helpers, Filling algorithm, ..\n",
    "\n",
    "\n",
    "#### 4. **Statistics Macros**\n",
    "- **Purpose:** Generate common analytical calculations\n",
    "- **Examples:** MRR calculations, churn rate formulas, cohort analysis, growth metrics or more technical sql calculation like window functions \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a8ef5",
   "metadata": {},
   "source": [
    "## F- Test Categories\n",
    "\n",
    "## Testing Strategy\n",
    "\n",
    "### Purpose and Vision\n",
    "\n",
    "Implement a **comprehensive testing framework** using dbt's generic tests, organized by test type to ensure data quality, integrity, and business logic validation across all layers. The strategy prioritizes maintainability through clear folder organization and reusable test definitions.\n",
    "\n",
    "---\n",
    "\n",
    "DBT is intersting tool to do testing but the way of implementing it isn't optimal specially the fact when we want to store failures it automatically create a table by test which that the number of test tables will grow by trying to put more tests. The proposed idea is the make create a central table that will store necessary meta-data that concern the model and tested column + the result of the test that we want store. That way we can have one centralized table of tests (by layer) that will allow us to do quality data dashboards + easily database mangement. And ofc if needed we can create some table per test if need more information about the issue.\n",
    "\n",
    "### Test Organization Structure\n",
    "\n",
    "Tests are organized in a dedicated folder hierarchy by test type for easy discovery and maintenance:\n",
    "\n",
    "\n",
    "\n",
    "#### 1. **Business Logic Tests**\n",
    "- **Purpose:** Enforce domain-specific rules and constraints\n",
    "- **Location:** `tests/generic/business_logic/`\n",
    "- **Test types:** Custom singular tests for business rules\n",
    "- **Applied to:** Silver and Gold layers where business logic is applied\n",
    "- **Example validations:**\n",
    "  - Active subscriptions must have MRR > 0\n",
    "  - Canceled subscriptions must have MRR = 0\n",
    "  - Customer creation date cannot be in the future\n",
    "  - Multi-module customers must have 2+ active subscriptions\n",
    "\n",
    "#### 2. **Data Quality Tests**\n",
    "- **Purpose:** Validate data formats, ranges, and accepted values\n",
    "- **Location:** `tests/generic/data_quality/`\n",
    "- **Test types:** `accepted_values`, range checks, format validation, null checks\n",
    "- **Applied to:** All layers, with strictest checks in Silver\n",
    "- **Example validations:**\n",
    "  - Subscription status is only 'active' or 'canceled'\n",
    "  - Module names match approved list (Awareness, Simulation, Sonar, Slash)\n",
    "  - MRR is non-negative\n",
    "  - Email addresses follow valid format\n",
    "  - Dates are within reasonable ranges\n",
    "\n",
    "#### 3. **Reconciliation Tests**\n",
    "- **Purpose:** Ensure data consistency across layers and aggregations\n",
    "- **Location:** `tests/generic/reconciliation/`\n",
    "- **Test types:** Custom cross-layer validation tests\n",
    "- **Applied to:** Between Bronze→Silver, Silver→Gold transitions\n",
    "- **Example validations:**\n",
    "  - Row counts match between Bronze and Silver after cleaning\n",
    "  - Total MRR in Gold equals sum of Silver subscription MRR\n",
    "  - Customer counts reconcile across segmentation models\n",
    "  - No data loss during transformations\n",
    "\n",
    "---\n",
    "\n",
    "### Test Execution by Layer\n",
    "\n",
    "| Layer | Primary Focus | Key Test Types |\n",
    "|-------|--------------|----------------|\n",
    "| **Bronze** | Identity & completeness | Primary keys, not null, freshness |\n",
    "| **Silver** | Data validity & relationships | All test types, strictest validation rules |\n",
    "| **Gold** | Aggregation accuracy & grain | Reconciliation, business metrics validation, grain checks |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286aa2eb",
   "metadata": {},
   "source": [
    "## G -Folder Organization\n",
    "\n",
    "```\n",
    "riot_analytics/\n",
    "│\n",
    "├── dbt_project.yml\n",
    "├── packages.yml\n",
    "│\n",
    "│── seeds/\n",
    "│      ├── sources.yml\n",
    "│      ├── stripe_subscriptions.sql\n",
    "│      └── stripe_customers.sql\n",
    "│\n",
    "│ ── macros\n",
    "│       ├── sql_core\n",
    "│       │   \n",
    "│       ├── normalization\n",
    "│       │ \n",
    "│       │── quality_compliance\n",
    "│       │\n",
    "│       └── stats\n",
    "│\n",
    "├── models/\n",
    "│   │── schema.yml (tests + documentation) \n",
    "│   ├── silver/\n",
    "│   │   ├── slv_stripe_subscriptions.sql\n",
    "│   │   └── slv_stripe_customers.sql\n",
    "│   │\n",
    "│   └── gold/\n",
    "│       │\n",
    "│       ├── star/\n",
    "│       │   ├── fct_subscriptions.sql \n",
    "│       │   ├── dim_customers.sql\n",
    "│       │   └── dim_plans.sql\n",
    "│       │\n",
    "│       ├── wide/\n",
    "|       │    ├── sales\n",
    "|       │    │      \n",
    "|       │    ├── product\n",
    "|       │    │ \n",
    "|       │    │── cross\n",
    "│       │   \n",
    "│       │   \n",
    "│       │\n",
    "│       └── joins/\n",
    "│           └── gld_subscriptions_customers.sql\n",
    "│\n",
    "│\n",
    "└── tests/\n",
    "    ├── assert_test3\n",
    "    ├── assert_test2\n",
    "    └── assert_test1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb967ca1",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa0599f",
   "metadata": {},
   "source": [
    "\n",
    "### Part 2: Write SQL queries\n",
    "\n",
    "Using the raw CSVs as source tables, write SQL to answer these business questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e32ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/2e/7c/870c7e7daec2a6c7ff2ac9e33b23317230d4e4e954b35112759ea4a924a7/pandas-3.0.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pandas-3.0.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.26.0 (from pandas)\n",
      "  Obtaining dependency information for numpy>=1.26.0 from https://files.pythonhosted.org/packages/1b/46/6fa4ea94f1ddf969b2ee941290cca6f1bfac92b53c76ae5f44afe17ceb69/numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./dbt_env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./dbt_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-3.0.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, pandas\n",
      "Successfully installed numpy-2.4.2 pandas-3.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d145de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('./data/riot_analytics.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640f095",
   "metadata": {},
   "source": [
    "\n",
    "**Query A - Customer Segmentation:**\n",
    "\n",
    "```markdown\n",
    "Calculate total MRR by customer segment as of today:\n",
    "- Organization customers (has organization_id)\n",
    "- Standalone customers (no organization_id)\n",
    "- Multi-module customers (2+ active subscriptions to different modules)\n",
    "\n",
    "Show: segment_name, customer_count, total_mrr, avg_mrr_per_customer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a329f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH customer_subscriptions AS (\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.metadata_organization_id,\n",
    "        COUNT(DISTINCT s.module) AS distinct_module_count,\n",
    "        SUM(CASE WHEN s.status = 'active' THEN s.mrr ELSE 0 END) AS total_mrr\n",
    "    FROM stripe_customers c\n",
    "    LEFT JOIN stripe_subscriptions s \n",
    "        ON c.customer_id = s.customer_id\n",
    "        AND s.status = 'active'\n",
    "    GROUP BY c.customer_id, c.metadata_organization_id\n",
    "),\n",
    "segmented AS (\n",
    "    SELECT customer_id, total_mrr, 'Organization customers' AS segment_name\n",
    "    FROM customer_subscriptions\n",
    "    WHERE metadata_organization_id IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT customer_id, total_mrr, 'Standalone customers' AS segment_name\n",
    "    FROM customer_subscriptions\n",
    "    WHERE metadata_organization_id IS NULL \n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT customer_id, total_mrr, 'Multi-module customers' AS segment_name\n",
    "    FROM customer_subscriptions\n",
    "    WHERE distinct_module_count >= 2\n",
    ")\n",
    "SELECT\n",
    "    segment_name,\n",
    "    COUNT(DISTINCT customer_id) AS customer_count,\n",
    "    SUM(total_mrr) AS total_mrr,\n",
    "    ROUND(AVG(total_mrr), 2) AS avg_mrr_per_customer\n",
    "FROM segmented\n",
    "GROUP BY segment_name\n",
    "ORDER BY total_mrr DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f08119f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_name</th>\n",
       "      <th>customer_count</th>\n",
       "      <th>total_mrr</th>\n",
       "      <th>avg_mrr_per_customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-module customers</td>\n",
       "      <td>15</td>\n",
       "      <td>41900</td>\n",
       "      <td>2793.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organization customers</td>\n",
       "      <td>15</td>\n",
       "      <td>38850</td>\n",
       "      <td>2590.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standalone customers</td>\n",
       "      <td>15</td>\n",
       "      <td>8400</td>\n",
       "      <td>560.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             segment_name  customer_count  total_mrr  avg_mrr_per_customer\n",
       "0  Multi-module customers              15      41900               2793.33\n",
       "1  Organization customers              15      38850               2590.00\n",
       "2    Standalone customers              15       8400                560.00"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03cac10",
   "metadata": {},
   "source": [
    "\n",
    "**Query B - Module Performance:**\n",
    "\n",
    "```markdown\n",
    "For each module, calculate:\n",
    "- Number of active subscriptions\n",
    "- Total MRR from active subscriptions\n",
    "- Average MRR per subscription\n",
    "- Churn rate (% of all-time subscriptions that have been canceled)\n",
    "\n",
    "Order by total MRR descending\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba31d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module</th>\n",
       "      <th>active_subscriptions</th>\n",
       "      <th>total_mrr</th>\n",
       "      <th>avg_mrr_per_subscription</th>\n",
       "      <th>churn_rate_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Awareness</td>\n",
       "      <td>26</td>\n",
       "      <td>28150</td>\n",
       "      <td>1082.69</td>\n",
       "      <td>10.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>6</td>\n",
       "      <td>7650</td>\n",
       "      <td>1275.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simulation</td>\n",
       "      <td>7</td>\n",
       "      <td>6400</td>\n",
       "      <td>914.29</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slash</td>\n",
       "      <td>6</td>\n",
       "      <td>5050</td>\n",
       "      <td>841.67</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       module  active_subscriptions  total_mrr  avg_mrr_per_subscription  \\\n",
       "0   Awareness                    26      28150                   1082.69   \n",
       "1       Sonar                     6       7650                   1275.00   \n",
       "2  Simulation                     7       6400                    914.29   \n",
       "3       Slash                     6       5050                    841.67   \n",
       "\n",
       "   churn_rate_pct  \n",
       "0           10.34  \n",
       "1            0.00  \n",
       "2           12.50  \n",
       "3           14.29  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH module_metrics AS (\n",
    "    SELECT\n",
    "        module,\n",
    "        COUNT(CASE WHEN status = 'active' THEN 1 END) AS active_subscriptions,  -- Active subscriptions\n",
    "        SUM(CASE WHEN status = 'active' THEN mrr ELSE 0 END) AS total_mrr,\n",
    "        ROUND(\n",
    "            AVG(CASE WHEN status = 'active' THEN mrr END), \n",
    "            2\n",
    "        ) AS avg_mrr_per_subscription, -- Average MRR per active subscription\n",
    "        -- Churn rate\n",
    "        COUNT(CASE WHEN status = 'canceled' THEN 1 END) AS canceled_subscriptions,\n",
    "        COUNT(*) AS all_time_subscriptions,\n",
    "        ROUND(\n",
    "            COUNT(CASE WHEN status = 'canceled' THEN 1 END) * 100.0 / COUNT(*),\n",
    "            2\n",
    "        ) AS churn_rate_pct\n",
    "    FROM stripe_subscriptions\n",
    "    GROUP BY module\n",
    ")\n",
    "SELECT\n",
    "    module,\n",
    "    active_subscriptions,\n",
    "    total_mrr,\n",
    "    avg_mrr_per_subscription,\n",
    "    churn_rate_pct\n",
    "FROM module_metrics\n",
    "ORDER BY total_mrr DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute and fetch results\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89bcc35",
   "metadata": {},
   "source": [
    "\n",
    "**Query C - Organization Analysis:**\n",
    "\n",
    "```markdown\n",
    "For each organization, show:\n",
    "- Organization ID\n",
    "- Number of workspaces (distinct customers in that org)\n",
    "- Total MRR across all workspaces\n",
    "- Comma-separated list of unique modules in use across the org\n",
    "- Earliest workspace creation date (when did this org first join RIOT?)\n",
    "\n",
    "Only include organizations with 2+ workspaces\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472e2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization_id</th>\n",
       "      <th>workspace_count</th>\n",
       "      <th>total_mrr</th>\n",
       "      <th>modules_in_use</th>\n",
       "      <th>earliest_workspace_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>org_052</td>\n",
       "      <td>2</td>\n",
       "      <td>9750</td>\n",
       "      <td>Simulation,Awareness,Slash</td>\n",
       "      <td>2024-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>org_056</td>\n",
       "      <td>2</td>\n",
       "      <td>8300</td>\n",
       "      <td>Simulation,Sonar,Awareness,Slash</td>\n",
       "      <td>2024-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>org_051</td>\n",
       "      <td>2</td>\n",
       "      <td>6350</td>\n",
       "      <td>Sonar,Awareness,Slash</td>\n",
       "      <td>2024-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>org_055</td>\n",
       "      <td>2</td>\n",
       "      <td>5450</td>\n",
       "      <td>Sonar,Awareness,Simulation</td>\n",
       "      <td>2024-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>org_053</td>\n",
       "      <td>2</td>\n",
       "      <td>3200</td>\n",
       "      <td>Sonar,Awareness,Simulation</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>org_050</td>\n",
       "      <td>3</td>\n",
       "      <td>2950</td>\n",
       "      <td>Simulation,Awareness,Slash</td>\n",
       "      <td>2024-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>org_054</td>\n",
       "      <td>2</td>\n",
       "      <td>2850</td>\n",
       "      <td>Awareness,Simulation</td>\n",
       "      <td>2024-04-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  organization_id  workspace_count  total_mrr  \\\n",
       "0         org_052                2       9750   \n",
       "1         org_056                2       8300   \n",
       "2         org_051                2       6350   \n",
       "3         org_055                2       5450   \n",
       "4         org_053                2       3200   \n",
       "5         org_050                3       2950   \n",
       "6         org_054                2       2850   \n",
       "\n",
       "                     modules_in_use earliest_workspace_created  \n",
       "0        Simulation,Awareness,Slash                 2024-01-30  \n",
       "1  Simulation,Sonar,Awareness,Slash                 2024-01-28  \n",
       "2             Sonar,Awareness,Slash                 2024-01-25  \n",
       "3        Sonar,Awareness,Simulation                 2024-04-15  \n",
       "4        Sonar,Awareness,Simulation                 2024-01-10  \n",
       "5        Simulation,Awareness,Slash                 2024-01-15  \n",
       "6              Awareness,Simulation                 2024-04-20  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH org_data AS (\n",
    "    SELECT\n",
    "        c.metadata_organization_id AS organization_id,\n",
    "        c.customer_id,\n",
    "        c.created_at,\n",
    "        s.module,\n",
    "        s.mrr\n",
    "    FROM stripe_customers c\n",
    "    LEFT JOIN stripe_subscriptions s\n",
    "        ON c.customer_id = s.customer_id\n",
    "        AND s.status = 'active'\n",
    "    WHERE c.metadata_organization_id IS NOT NULL \n",
    "),\n",
    "org_metrics AS (\n",
    "    SELECT\n",
    "        organization_id,\n",
    "        COUNT(DISTINCT customer_id) AS workspace_count,\n",
    "        SUM(COALESCE(mrr, 0)) AS total_mrr,\n",
    "        GROUP_CONCAT(DISTINCT module) AS modules_in_use,\n",
    "        MIN(created_at) AS earliest_workspace_created\n",
    "    FROM org_data\n",
    "    GROUP BY organization_id\n",
    "    HAVING COUNT(DISTINCT customer_id) >= 2\n",
    ")\n",
    "SELECT\n",
    "    organization_id,\n",
    "    workspace_count,\n",
    "    total_mrr,\n",
    "    modules_in_use,\n",
    "    earliest_workspace_created\n",
    "FROM org_metrics\n",
    "ORDER BY total_mrr DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute and fetch results\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e825256",
   "metadata": {},
   "source": [
    "\n",
    "### Part 3: Data Quality\n",
    "\n",
    "What **dbt tests** would you add to ensure data quality?\n",
    "\n",
    "List at least **6-8 tests** across your models. For each test, specify:\n",
    "\n",
    "- Model/table name\n",
    "- Column(s) being tested\n",
    "- Test type (unique, not_null, relationships, accepted_values, custom, etc.)\n",
    "- Why this test matters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabc0cf0",
   "metadata": {},
   "source": [
    "1. Unique customer IDs (bronze layer)\n",
    "\n",
    "- Model name: stripe_customers\n",
    "- Column: customer_id\n",
    "- Test type: unique, not_null\n",
    "- Why this test matters: Customer ID is the primary key. We should ensure that there is no duplicates that will break downstream joins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b95b9",
   "metadata": {},
   "source": [
    "2. Unique subscription IDs (Bronze layer)\n",
    "\n",
    "- Model name: stripe_subscriptions\n",
    "- Column: subscription_id\n",
    "- Test type: unique, not_null\n",
    "- Why this test matters:Subscription ID is alse the primary key, duplicates might inflate MRR calculations and subscription counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69361386",
   "metadata": {},
   "source": [
    "3. Referential integrity: subscriptions and customers (Silver layer)\n",
    "\n",
    "- Model name: slv_stripe_subscriptions\n",
    "- Column: customer_id\n",
    "- Test type: relationships\n",
    "- Why this test matters: Every subscription must belong to a valid customer. Orphaned subscriptions for example might cause incorrect segmentation (since we will not find a corresponding organisation )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82010e9a",
   "metadata": {},
   "source": [
    "4. Non-negative MRR (Silver layer)\n",
    "\n",
    "- model: slv_stripe_subscriptions\n",
    "- column: mrr\n",
    "- Test type: assert_non_negative\n",
    "- Why it matters: Negative MRR is a data error that would understate revenue. Active subscriptions should have MRR ≥ 0 (canceled subs have MRR = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a99f7",
   "metadata": {},
   "source": [
    "5. Consistent module names\n",
    "- Model name: slv_stripe_subscriptions\n",
    "- Column: module\n",
    "- Test type: accepted_values\n",
    "- Why this test matters: Typos or case inconsistencies ('awareness', 'AWARENESS') would break multi-module customer identification and module-level reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80cef2",
   "metadata": {},
   "source": [
    "6. Row count reconcilation\n",
    "- Model: fct_subscriptions\n",
    "- Test type: reconcilation test (verify if fact subscriptions number and silver layer subscriptions layer are the same)\n",
    "- Why it matters: If grain is subscription, row counts should match. Differences indicate filtering errors or duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5699fb",
   "metadata": {},
   "source": [
    "7. Customer segmentation: All customers classified\n",
    "- Model: gld_customer_segment (if created following dbt modelisation logic above)\n",
    "- column: segment_type\n",
    "- test type: not_null, accepted_values\n",
    "- Why it matters: Every customer must be assigned to exactly one segment. NULLs or invalid values break segmentation reporting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbt_env (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
